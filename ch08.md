# 第八章 部署

> 要想把python程序付诸应用,就必须把它从开发环境部署到生产环境之中.令程序支持好几套不同的配置方案颇有些难度.因此我们要设法让程序在各种情境下都能可靠的运作,这与实现正确的功能是一样重要的.

## 第54条: 考虑用模块级别的代码来配置不同的部署环境

> 所谓部署环境(deployment environment)就是程序在运行的时候所用的一套配置.每个程序至少都会有一种部署环境,这就是生产环境(production environment).
>
> 但是,在编写代码和修改程序代码的过程中,我们必须要在开发环境中进行,它与生产环境有很大的区别.
>
> pyvenv等工具(参见第53条)使得开发者能够保证所有的环境都装有同一套python软件包.
>
> 但问题在于,生产环境通常还会依赖很多外部的先决条件(external assumption),而这些先决条件,很难在开发环境里重现.

```python
'''
例如,在web服务器容器中运行某个程序,并通过该程序访问数据库,那么,每次修改完程序的代码,我们都要把服务器容器运行起来,把数据库设置好,并输入访问数据库所需的密码.

解决此类问题的最佳方案:在程序启动的时候,覆写其中的某些部分,以便根据部署环境,来提供不同的功能.例如,编写两份不同的__main__文件,一份用于生产环境,另一份用于开发环境.
'''
# dev_main.py
TESTING = True
import db_connection
db = db_connection.Database()

#prod_main.py
TESTING = False
import db_connection
db = db_connection.Database()

'''
两份代码的唯一区别在于TESTING常量的取值.于是,程序中的其他模块可通过TESTING的值来决定如何定义自身的属性

也可以考虑使用配置文件来实现此功能.
'''
```



### 要点

- 程序通常需要运行在各种不同的部署环境之中,而这些环境所需的先决条件及配置信息,也都互不相同
- 我们可以在模块范围内,编写普通的python语句,以便根据不同的部署环境,来定制本模块的内容
- 我们可以根据外部条件来决定模块的内容,例如,通过sys和os模块来查询宿主操作系统的特性,并以此来定义本模块中的相关结构.



## 第55条:通过repr字符串来输出调试信息

> 调试python程序时,print函数(以及内置的logging模块中的那些输出函数)可以给我们极大的帮助.由于python的内部信息,一般都可以通过普通的属性来获取(参见第27条)

### 要点

- 针对内置的python类型来调用print函数,会根据该值打印出一条易于阅读的字符串,这个字符串隐藏了类型信息

- 针对内置的python类型来调用repr函数,会根据该值返回一条可供打印的字符串.把这个repr字符串传给内置的eval函数,就可以将其还原为原始的那个值.

- 在格式化字符串里使用%s,能够产生与str函数的返回值相仿的易读字符串

  而在格式化字符串里使用%r,则能够产生与repr函数的返回值相仿的可打印字符串.

- 可以在类中编写__repr\_\_方法,用自定义的方式来提供一种可供打印的字符串,并在其中给出更为详细的调试信息

- 可以在任意对象上面查询__dict\_\_属性,以观察其内部信息



## 第56条:用unittest来测试全部代码

> python没有静态类型检查机制.编译器不能保证程序一定会在运行的时候正确地执行.
>
> python语言与其他编程语言相比,确实有个显著的区别,那就是只有通过编写测试,我们才能够确信程序在运行的时候不会出问题.我们不能通过静态类型检查来获得安全感.

```python
#util.py
def to_str(data):
    if isinstance(data, str):
        return data
    elif isinstance(data, bytes):
        return data.decode('utf-8')
    else:
        raise TypeError('Must supply str or bytes, found: %r' %data)
        
# utils_test.py
from unittest import TestCase, main
from utils import to_str
class UtilsTestCase(TestCase):
    def test_to_str_bytes(self):
        self.assertEqual('hello', to_str(b'hello'))
        
    def test_to_str_str(self):
        self.assertEqual('hello', to_str('hello'))
        
    def test_to_str_bad(self):
        self.assertRaises(TypeError, to_str, object())
        
if __name__ == '__main__':
    main()
    
'''
编写测试时,还有一种常用的方法,就是通过mock函数或mock类来替换受测程序中的某些行为.

有的时候,在运行测试方法之前,需要现在TestCase类里面把测试环境配置好,于是需要覆写setUp和tearDown方法.系统在执行每个测试之前,都会调用各项测试之间,可以彼此独立运行.
'''
class MyTest(TestCase):
    def setUp(self):
        self.test_dir = TemporaryDirectory()
    def tearDown(self):
        self.test_dir.cleanup()
'''
通常我们会把一组相关的测试,放入一个TestCase子类中;比如某函数有很多种边界状况需要测试,那就针对这个函数转本编写一个TestCase子类.其他情况下,可能会把某个模块内的所有函数,全部放在同一个子类里面测试.另外,也会针对每个类编写TestCase,以便测试该类及类中的所有方法.

当程序变得复杂之后,我们还可能要编写另外一些测试.这种测试并不是孤立的检验各个模块,而是要验证模块之间能够正确的互动.这就是单元测试和集成测试(integration test)的区别.

有些项目可能还需要定义数据驱动测试(data-driven test),或是需要把测试项目按照功能划分到不同的套件(suite)之中.关于这些用法,以及测试覆盖度报告和其他一些高级用法,请参见nose(nose.readthedocs.org)和pytest(pytest.org)等开源软件包
'''
```



### 要点

- 要想确信python程序能够正常运行,唯一的办法就是编写测试
- 内置的unittest模块提供了测试者所需的很多功能,我们可以借助这些机制写出良好的测试
- 我们可以在TestCase子类中,为每一个需要测试的行为,定义对应的测试方法.TestCase子类里的测试方法,其名称必须以test开头
- 我们必须同时编写单元测试和集成测试,前者用来独立检验程序中的每个功能,而后者则用来检验模块之间的交互行为.



## 第57条:考虑用pdb实现交互调试

> 编写程序的时候,我们总会遇到bug.print函数可以帮我们追查到很多问题的来源(参见第55条).
>
> 如果要使用更为强大的调试工具,那就请试试python内置的交互调试器.这种调试器能够检视程序的状态,打印局部变量,并能够以步进的方式来执行程序中的每一条语句
>
> 调试器的命令:
>
> - bt:针对当前执行点的调用栈,打印其回溯(traceback)信息.可以据此判断出程序当前执行到了哪个信息,也可以看出程序是如何从最开头运行到触发pdb.set_trace函数的这一点的.
> - up:把调试范围沿着函数调用栈上移一层,回到当前函数的调用者那里.该命令使得我们可以检视调用栈上层的局部变量.
> - down:把调试范围沿着函数调用栈下移一层.
> - step:执行当前这行代码,并把程序继续运行到下一条可执行的语句开头,然后把控制权交还给调试器.如果当前这行代码中带有函数调用操作,那么调试器会进入受调用的那个函数,并停留在那个函数开头.
> - next:执行当前这行代码,并把程序继续运行到下一条可执行的语句开头,然后把控制权交还给调试器.如果当前这行代码中带有函数调用操作,那么调试器不会停留在函数里面,而是会调用那个函数,并等待其返回.
> - return:继续运行程序,直至到达当前函数的return语句开头,然后把控制权交还给调试器
> - continue:继续运行程序,直至到达下一个断点或下一个set_trace调用点.



### 要点

- 我们可以修改python程序,在想要调试的代码上方直接加入import pdb;pdb.set_trace()语句,以触发互动调试器
- python调试器也是一个完整的python提示符界面,我们可以检视并修改受测程序的状态
- 我们可以在pdb提示符中输入命令,以便精确地控制程序的执行流程,这些命令使得我们能够交替的查看程序状态并继续向下运行程序.



## 第58条: 先分析性能,然后再优化

> python是一门动态语言，所以它的运行速率可能与我们预想的结果有很大的区别。
>
> 应对性能问题的最佳方式，是在优化程序之前先分析其性能，而不是靠直觉去判断。python提供了内置的性能分析工具（profiler），它可以计算出程序中某个部分的执行之间，在总体执行时间中所占的比率。通过这些数据，可以找到最为显著的性能瓶颈，并把注意力放在优化这部分代码上面，而不要在不影响速度的那些地方浪费精力。

```python
def insertion_sort(data):
    result = []
    for value in data:
        insert_value(result, value)
	return result

def insert_value(array, value):
    for i, existing in enumerate(array):
        if existing>value:
            array.insert(i, value)
            return
    array.append(value)
    
from random import randint
max_size = 10**4
data = [randint(0, max_size) for _ in range(max_size)]
test = lambda: insertion_sort(data)

'''
python提供了两种内置的profiler，一种是纯python的profiler（名字叫做profile），另外一种是C语言扩展模块（叫做cProfile）。

在这两者中，内置的cProfile模块更好，因为它在做性能分析时，对受测程序的效率只会产生很小的影响，而纯python版的profiler，则会产生较大的开销，从而使测试结果变得不够准确。
'''
profiler = Profile()
profiler.runcall(test)
stats = Stats(profiler)
stats.strip_dirs()
stats.sort_stats('cumulative')
stats.print_stats()

'''
性能统计表中每一列的含义：
1. ncalls:该函数在性能分析期间的调用次数
2. tottime：执行该函数所花的总秒数。本函数因调用其他函数所耗费的时间，不计入在内
3. tottime percall： 每次调用该函数所花的平均秒数。本函数因调用其他函数所耗费的时间，不计入在内。此值等于tottime与ncalls相除的商
4. cumtime：执行该函数及其中的全部函数调用操作所花的总秒数
5. cumtime percall:每次执行该函数及其中的全部函数调用操作，所花的平均秒数。此值等于cumtime与ncalls相除的商
'''
from bisect import bisect_left
def insert_value(array, value):
    i = bisect_left(array, value)
    array.insert(i, value)
    
'''
有时分析整个程序的性能时，可能会发现，某个常用的工具函数，占据了大部分执行时间。而从profiler所给出的默认统计数据里，我们却无法清晰的分辨出，程序中的不同部分，究竟是如何调用这个工具函数的。

也就是说，无法知道具体在那个函数中调用该工具函数所用的时间最多？
解决方案：stats.print_callers()
'''
```



### 要点

- 优化python程序之前，一定要先分析其性能，因为Python程序的性能瓶颈通常很难直接观察出来
- 做性能分析时，应该使用cProfile模块，而不要使用profile模块，因为前者能够给出更为精确的性能分析数据。
- 我们可以通过Profile对象的runcall方法来分析程序的性能，该方法能够提供性能分析所需的全部信息，它会按照树状的函数调用关系，来单独地统计每个函数的性能。
- 我们可以用Stats对象来筛选性能分析数据，并打印出我们所需的那一部分，以便据此了解程序的性能。



## 第59条：用tracemalloc来掌握内存的使用及泄露情况

> 在python的默认实现方式，也就是CPython中，内存管理是通过引用计数来处理的。这样做可以保证：当指向某个对象的全部引用都过期的时候，受引用的这个对象也能够同时得到清理。
>
> CPython内置了循环检测器（cycle detector），使得垃圾回收机制能够把那些自我引用的对象清理掉。
>
> 调试内存使用状况的第一种方法，是向内置的gc模块进行查询，请它列出垃圾收集器当前所知的每个对象。

```python
#using_gc.py
import gc
found_objects = gc.get_objects()
print('%d objects before' % len(found_objects))

a = 1
b = a
found_objects = gc.get_objects()
print('%d objects after' % len(found_objects))
for obj in found_objects[:3]:
    print(repr(obj)[:100])
    
'''
gc.get_objects函数的缺点是,它不能高数我们这些对象到底是如何分配出来的.

在较为复杂的程序中,代码会以多种不同的方式,来分配某个类的对象,所以,我们不仅要知道对象的总数量,而且更为重要的是,要知道这些对象究竟是由哪一部分代码分配出来的,了解到这一信息,才可以更好的判断内存泄露的原因.

python3.4推出新的内置模块tracemalloc,它可以解决这个问题.用tracemalloc打印出导致内存用量增大的前三个对象.
'''
# top_n.py
import tracemalloc
tracemalloc.start(10)  # save up to 10 stack frames

time1 = tracemalloc.take_snapshot()
a = 1
b = a
time2 = tracemalloc.take_snapshot()

stats = time2.compare_to(time1, 'lineno')
for stat in stats[:3]:
    print(stat)
    
'''
tracemalloc模块也可以打印出Python系统在执行每一个分配内存操作时,所具备的完整堆栈信息(full stack trace),打印的最大栈帧数量,由传给start函数的参数来决定
'''
#with_trace.py
stats = time2.compare_to(time1, 'traceback')
top = stats[0]
print('\n'.join(top.traceback.format()))
```



> python2虽然没有内置的tracemalloc模块,但是有许多开源软件包(heapy,pypi.python.org/pypi/guppy),也可以追踪内存用量,然而它们在功能上面,与tracemalloc并不是完全相同的.



### 要点

- Python程序的内存使用情况和内存泄露情况是很难判断的
- 我们虽然可以通过gc模块来了解程序中的对象,但是并不能由此看出这些对象究竟是如何分配出来的
- 内置的tracemalloc模块提供了许多强大的工具,使得我们可以找出导致内存使用量增大的根源.
- 只有Python3.4及后续版本才支持tracemalloc模块